{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b281ef1b",
   "metadata": {},
   "source": [
    "# GoingDeeper2 : 멋진 단어사전 만들기\n",
    "\n",
    "1. Rubrics\n",
    "    * 코퍼스 분석, 전처리, SentencePiece 적용, 토크나이저 구현 및 동작이 빠짐없이 진행되었는가?\n",
    "    * SentencePiece 토크나이저가 적용된 Text Classifier 모델이 정상적으로 수렴하여 80% 이상의 test accuracy가 확인되었다.\n",
    "    * SentencePiece 토크나이저를 활용했을 때의 성능을 다른 토크나이저 혹은 SentencePiece의 다른 옵션의 경우와 비교하여 분석을 체계적으로 진행하였다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf90dcc9",
   "metadata": {},
   "source": [
    "## 1.1 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b73cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n",
      "0.5.2\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from konlpy.tag import Mecab, Hannanum, Komoran\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import konlpy\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(konlpy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14cd818",
   "metadata": {},
   "source": [
    "### 데이터 불러오기 및 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b5fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/aiffel/aiffel/aiffel/nsmc-master/\"\n",
    "data_path = dir_path + \"ratings.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b42653",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table(data_path)\n",
    "data = data[['document','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d948ee7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  label\n",
       "0                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6acec54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09fe8e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>이런영화로 관객들한테 돈벌고싶소?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>작품 선구안이 없다는게 배우 김태희의 최대 약점.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>사극?? 로멘스?? 퓨젼??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>ㅋㅋㅋㅋ엿국니네가그렇지므ㅝ 이건뭐 영화도아니고</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>완죤유치하고 못봐주겠네...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>포켓 몬스터 짜가 ㅡㅡ;;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>쓰.레.기</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>완전 사이코영화. 마지막은 더욱더 이 영화의질을 떨어트린다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>왜난 재미없었지 ㅠㅠ 라따뚜이 보고나서 스머프 봐서 그런가 ㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>포풍저그가나가신다영차영차영차</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   document  label\n",
       "100000                   이런영화로 관객들한테 돈벌고싶소?      0\n",
       "100001          작품 선구안이 없다는게 배우 김태희의 최대 약점.      0\n",
       "100002                      사극?? 로멘스?? 퓨젼??      0\n",
       "100003            ㅋㅋㅋㅋ엿국니네가그렇지므ㅝ 이건뭐 영화도아니고      0\n",
       "100004                      완죤유치하고 못봐주겠네...      0\n",
       "...                                     ...    ...\n",
       "199995                       포켓 몬스터 짜가 ㅡㅡ;;      0\n",
       "199996                                쓰.레.기      0\n",
       "199997    완전 사이코영화. 마지막은 더욱더 이 영화의질을 떨어트린다.      0\n",
       "199998  왜난 재미없었지 ㅠㅠ 라따뚜이 보고나서 스머프 봐서 그런가 ㅋㅋ      0\n",
       "199999                      포풍저그가나가신다영차영차영차      0\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.label == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69150eb",
   "metadata": {},
   "source": [
    "#### remark\n",
    "\n",
    "1. 네이버 리뷰 데이터가 총 20만 개임을 알 수 있다.\n",
    "\n",
    "2. label은 0과 1로 구성되어 있으며 1은 긍정, 0은 부정을 의미한다.\n",
    "\n",
    "3. 데이터의 label이 1인 것이 앞의 절반, 0인 것이 뒤의 절반으로 완전히 분리되어있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c147a4",
   "metadata": {},
   "source": [
    "## 1.2 데이터 전처리_1\n",
    "\n",
    "1. 결측치 삭제\n",
    "2. 문장 길이의 평균 기준 +- 1표준편차 만큼 데이터 삭제\n",
    "    * 결과적으로 20만개 문장에서 163912 문장으로 줄어들 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064c5104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46471</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60735</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77665</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84098</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127017</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172375</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173526</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197279</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       document  label\n",
       "46471       NaN      1\n",
       "60735       NaN      1\n",
       "77665       NaN      1\n",
       "84098       NaN      1\n",
       "127017      NaN      0\n",
       "172375      NaN      0\n",
       "173526      NaN      0\n",
       "197279      NaN      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.document.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43fa2144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [document, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.label.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1016cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset = ['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8fece06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199992, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebcc1930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194543, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.document.nunique(), data.label.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f498e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7015a6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       document\n",
       "label          \n",
       "0         97277\n",
       "1         97266"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98f30daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  어릴때보고 지금다시봐도 재밌어요ㅋㅋ\n",
       "1    디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...\n",
       "2                 폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.\n",
       "3    와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...\n",
       "4                          안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.\n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.document[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7f26143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    \n",
    "    text = re.sub(\"[^ 가-힣]\",\"\",text)\n",
    "    text = re.sub(\"\\s+\", \" \",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ec6cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.document = data.document.apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aef8ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.document.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3da46b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_length(text):\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2611bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"document_length\"] = data.document.apply(text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50f3b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"document\",\"document_length\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60992726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>document_length</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  document_length  label\n",
       "0                                  어릴때보고 지금다시봐도 재밌어요               17      1\n",
       "1  디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...              134      1\n",
       "2                   폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고               32      1\n",
       "3   와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지               48      1\n",
       "4                         안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화               26      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2bb70a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>document_length</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198033</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198364</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199271</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199321</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199848</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>652 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       document  document_length  label\n",
       "111                            0      1\n",
       "190                            0      1\n",
       "203                            0      1\n",
       "984                            0      1\n",
       "1199                           0      1\n",
       "...         ...              ...    ...\n",
       "198033                         0      0\n",
       "198364                         0      0\n",
       "199271                         0      0\n",
       "199321                         0      0\n",
       "199848                         0      0\n",
       "\n",
       "[652 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.document_length == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b65419ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data[data.document_length == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad286dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>document_length</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  document_length  label\n",
       "0                                  어릴때보고 지금다시봐도 재밌어요               17      1\n",
       "1  디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...              134      1\n",
       "2                   폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고               32      1\n",
       "3   와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지               48      1\n",
       "4                         안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화               26      1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec01db1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193891, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db1f780a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 193891\n",
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 140\n",
      "문장의 평균 길이: 32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = data.document\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "    \n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "    \n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title('Sentence Length Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bce17758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    193891.000000\n",
       "mean         32.588588\n",
       "std          27.856685\n",
       "min           1.000000\n",
       "25%          14.000000\n",
       "50%          24.000000\n",
       "75%          39.000000\n",
       "max         140.000000\n",
       "Name: document_length, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.document_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bd3ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(5<= data.document_length) & (data.document_length <= 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76bba26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 163912\n",
      "문장의 최단 길이: 5\n",
      "문장의 최장 길이: 60\n",
      "문장의 평균 길이: 24\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = data.document\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "    \n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "    \n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title('Sentence Length Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e106b6",
   "metadata": {},
   "source": [
    "## 1.3 데이터 전처리_2\n",
    "\n",
    "1. mecab / komoran / hannanum 별로 개별 토크나이징\n",
    "\n",
    "2. 이를 데이터프레임에 적용\n",
    "\n",
    "3. 이후 토크나이징 할 때 등장 횟수가 4번 이하인 희귀 토큰은 단어장에 반영하지 않고 unk 토큰으로 처리할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e88124",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "komoran = Komoran()\n",
    "hannanum = Hannanum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cf1ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab_data = data.copy()\n",
    "komoran_data = data.copy()\n",
    "hannanum_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7adfde7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_pre(corpus, vocab_size=None):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='',num_words = vocab_size)\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre')\n",
    "    \n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2009c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_post(corpus, vocab_size=None):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', num_words = vocab_size)\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre')\n",
    "    \n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9010a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecab_split(text):\n",
    "    return mecab.morphs(text)\n",
    "\n",
    "def komoran_split(text):\n",
    "    return komoran.morphs(text)\n",
    "\n",
    "def hannanum_split(text):\n",
    "    return hannanum.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88f5802a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '에게', '는', '꿈', '이', '있', '습니다']\n",
      "['나', '에게', '는', '꿈', '이', '있', '습니다']\n",
      "['나', '에게는', '꿈', '이', '있', '습니다']\n"
     ]
    }
   ],
   "source": [
    "print(mecab_split(\"나에게는 꿈이 있습니다\"))\n",
    "print(komoran_split(\"나에게는 꿈이 있습니다\"))\n",
    "print(hannanum_split(\"나에게는 꿈이 있습니다\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03949059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "java.lang.ArrayIndexOutOfBoundsException: Index 10000 out of bounds for length 10000\n",
      "\tat kr.ac.kaist.swrc.jhannanum.plugin.MajorPlugin.PosTagger.HmmPosTagger.HMMTagger.new_mnode(HMMTagger.java:354)\n",
      "\tat kr.ac.kaist.swrc.jhannanum.plugin.MajorPlugin.PosTagger.HmmPosTagger.HMMTagger.tagPOS(HMMTagger.java:143)\n",
      "\tat kr.ac.kaist.swrc.jhannanum.hannanum.Workflow.analyzeInSingleThread(Workflow.java:857)\n",
      "\tat kr.ac.kaist.swrc.jhannanum.hannanum.Workflow.analyze(Workflow.java:521)\n",
      "\tat kr.lucypark.jhannanum.comm.HannanumInterface.simplePos09(Unknown Source)\n"
     ]
    }
   ],
   "source": [
    "mecab_data[\"mecab_corpus\"] = mecab_data.document.apply(mecab_split)\n",
    "komoran_data[\"komoran_corpus\"] = komoran_data.document.apply(komoran_split)\n",
    "hannanum_data[\"hannanum_corpus\"] = hannanum_data.document.apply(hannanum_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f69e090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>document_length</th>\n",
       "      <th>label</th>\n",
       "      <th>mecab_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199994</th>\n",
       "      <td>개연성이 없어요 별루다</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>[개연, 성, 이, 없, 어요, 별루, 다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>포켓 몬스터 짜가</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>[포켓, 몬스터, 짜, 가]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>완전 사이코영화 마지막은 더욱더 이 영화의질을 떨어트린다</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>[완전, 사이코, 영화, 마지막, 은, 더욱더, 이, 영화, 의, 질, 을, 떨어트...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>왜난 재미없었지 라따뚜이 보고나서 스머프 봐서 그런가</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>[왜, 난, 재미없, 었, 지, 라따뚜이, 보, 고, 나, 서, 스머프, 봐서, 그런가]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>포풍저그가나가신다영차영차영차</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>[포, 풍, 저그, 가, 나가, 신다, 영차영차, 영차]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               document  document_length  label  \\\n",
       "199994                     개연성이 없어요 별루다               12      0   \n",
       "199995                       포켓 몬스터 짜가                10      0   \n",
       "199997  완전 사이코영화 마지막은 더욱더 이 영화의질을 떨어트린다               31      0   \n",
       "199998   왜난 재미없었지 라따뚜이 보고나서 스머프 봐서 그런가                30      0   \n",
       "199999                  포풍저그가나가신다영차영차영차               15      0   \n",
       "\n",
       "                                             mecab_corpus  \n",
       "199994                           [개연, 성, 이, 없, 어요, 별루, 다]  \n",
       "199995                                    [포켓, 몬스터, 짜, 가]  \n",
       "199997  [완전, 사이코, 영화, 마지막, 은, 더욱더, 이, 영화, 의, 질, 을, 떨어트...  \n",
       "199998  [왜, 난, 재미없, 었, 지, 라따뚜이, 보, 고, 나, 서, 스머프, 봐서, 그런가]  \n",
       "199999                    [포, 풍, 저그, 가, 나가, 신다, 영차영차, 영차]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6e78633",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab_result = []\n",
    "\n",
    "for i, x in zip(mecab_data.index, mecab_data.mecab_corpus):\n",
    "    if len(x) == 0:\n",
    "        mecab_result.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a904ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran_result = []\n",
    "\n",
    "for i, x in zip(komoran_data.index, komoran_data.komoran_corpus):\n",
    "    if len(x) == 0:\n",
    "        komoran_result.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86f9e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hannanum_result = []\n",
    "\n",
    "for i, x in zip(hannanum_data.index, hannanum_data.hannanum_corpus):\n",
    "    if len(x) == 0:\n",
    "        hannanum_result.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66e126a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[25647]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(mecab_result, len(mecab_result), sep=\"\\n\")\n",
    "print(komoran_result, len(komoran_result), sep=\"\\n\")\n",
    "print(hannanum_result, len(hannanum_result), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a9c963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = list((set(mecab_result) | set(komoran_result)) | set(hannanum_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962dfbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb5f43aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab_data = mecab_data.drop(result)\n",
    "komoran_data = komoran_data.drop(result)\n",
    "hannanum_data = hannanum_data.drop(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8bb53f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[mecab_data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02694862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ded7c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab_tensor_pre, mecab_tokenizer_pre = tokenize_pre(mecab_data.mecab_corpus)\n",
    "mecab_tensor_post, mecab_tokenizer_post = tokenize_post(mecab_data.mecab_corpus)\n",
    "\n",
    "komoran_tensor_pre, komoran_tokenizer_pre = tokenize_pre(komoran_data.komoran_corpus)\n",
    "komoran_tensor_post, komoran_tokenizer_post = tokenize_post(komoran_data.komoran_corpus)\n",
    "\n",
    "hannanum_tensor_pre, hannanum_tokenizer_pre = tokenize_pre(hannanum_data.hannanum_corpus)\n",
    "hannanum_tensor_post, hannanum_tokenizer_post = tokenize_post(hannanum_data.hannanum_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4b733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "898545b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mecab 단어 집합(vocabulary)의 크기 : 44018\n",
      "mecab tensoor 중 등장 빈도가 4번 이하인 희귀 단어의 수: 30415\n",
      "mecab 단어 집합에서 희귀 단어의 비율: 69.097 %\n",
      "mecab 전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.489 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 5\n",
    "total_cnt = len(mecab_tokenizer_post.word_index)\n",
    "rare_cnt = 0\n",
    "\n",
    "total_freq = 0\n",
    "rare_freq = 0\n",
    "\n",
    "\n",
    "for key, value in mecab_tokenizer_post.word_counts.items():\n",
    "    total_freq += value\n",
    "    \n",
    "    if value < threshold:\n",
    "        rare_cnt += 1\n",
    "        rare_freq += value\n",
    "        \n",
    "print('mecab 단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('mecab tensoor 중 등장 빈도가 {}번 이하인 희귀 단어의 수: {}'.format(threshold - 1, rare_cnt))\n",
    "print(\"mecab 단어 집합에서 희귀 단어의 비율:\", round((rare_cnt / total_cnt)*100,3),\"%\")\n",
    "print(\"mecab 전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", round((rare_freq / total_freq)*100,3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "250a7fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기:  13604\n"
     ]
    }
   ],
   "source": [
    "mecab_vocab_size = total_cnt - rare_cnt + 1\n",
    "print(\"단어장의 크기: \", mecab_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b876d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32c3f9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "komoran 단어 집합(vocabulary)의 크기 : 39539\n",
      "komoran tensoor 중 등장 빈도가 4번 이하인 희귀 단어의 수: 27843\n",
      "komoran 단어 집합에서 희귀 단어의 비율: 70.419 %\n",
      "komoran 전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.94 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 5\n",
    "total_cnt = len(komoran_tokenizer_post.word_index)\n",
    "rare_cnt = 0\n",
    "\n",
    "total_freq = 0\n",
    "rare_freq = 0\n",
    "\n",
    "\n",
    "for key, value in komoran_tokenizer_post.word_counts.items():\n",
    "    total_freq += value\n",
    "    \n",
    "    if value < threshold:\n",
    "        rare_cnt += 1\n",
    "        rare_freq += value\n",
    "        \n",
    "print('komoran 단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('komoran tensoor 중 등장 빈도가 {}번 이하인 희귀 단어의 수: {}'.format(threshold - 1, rare_cnt))\n",
    "print(\"komoran 단어 집합에서 희귀 단어의 비율:\", round((rare_cnt / total_cnt)*100,3),\"%\")\n",
    "print(\"komoran 전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", round((rare_freq / total_freq)*100,3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51878a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기:  11697\n"
     ]
    }
   ],
   "source": [
    "komoran_vocab_size = total_cnt - rare_cnt + 1\n",
    "print(\"단어장의 크기: \", komoran_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a2b8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3017ca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hannanum 단어 집합(vocabulary)의 크기 : 147929\n",
      "hannanum tensoor 중 등장 빈도가 4번 이하인 희귀 단어의 수: 135174\n",
      "hannanum 단어 집합에서 희귀 단어의 비율: 91.378 %\n",
      "hannanum 전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 9.306 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 5\n",
    "total_cnt = len(hannanum_tokenizer_post.word_index)\n",
    "rare_cnt = 0\n",
    "\n",
    "total_freq = 0\n",
    "rare_freq = 0\n",
    "\n",
    "for key, value in hannanum_tokenizer_post.word_counts.items():\n",
    "    total_freq += value\n",
    "    \n",
    "    if value < threshold:\n",
    "        rare_cnt += 1\n",
    "        rare_freq += value\n",
    "        \n",
    "print('hannanum 단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('hannanum tensoor 중 등장 빈도가 {}번 이하인 희귀 단어의 수: {}'.format(threshold - 1, rare_cnt))\n",
    "print(\"hannanum 단어 집합에서 희귀 단어의 비율:\", round((rare_cnt / total_cnt)*100,3),\"%\")\n",
    "print(\"hannanum 전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", round((rare_freq / total_freq)*100,3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "491ddf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기:  12756\n"
     ]
    }
   ],
   "source": [
    "hannanum_vocab_size = total_cnt - rare_cnt + 1\n",
    "print(\"단어장의 크기: \", hannanum_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6356e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2cfb079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab_tensor_pre, mecab_tokenizer_pre = tokenize_pre(mecab_data.mecab_corpus, vocab_size = 12000)\n",
    "mecab_tensor_post, mecab_tokenizer_post = tokenize_post(mecab_data.mecab_corpus, vocab_size = 12000)\n",
    "\n",
    "komoran_tensor_pre, komoran_tokenizer_pre = tokenize_pre(komoran_data.komoran_corpus, vocab_size = 12000)\n",
    "komoran_tensor_post, komoran_tokenizer_post = tokenize_post(komoran_data.komoran_corpus, vocab_size = 12000)\n",
    "\n",
    "hannanum_tensor_pre, hannanum_tokenizer_pre = tokenize_pre(hannanum_data.hannanum_corpus, vocab_size = 12000)\n",
    "hannanum_tensor_post, hannanum_tokenizer_post = tokenize_post(hannanum_data.hannanum_corpus, vocab_size = 12000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8baece",
   "metadata": {},
   "source": [
    "#### remark\n",
    "\n",
    "1. 5번 이상인 단어의 집합이 전체적으로 11000에서 13000 사이로 나오고 있어서 vocab size를 12000으로 잡았다.\n",
    "\n",
    "2. 이를 기준으로 sentence piece tokenizer의 단어장 사이즈도 12000으로 잡을 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53eadc9",
   "metadata": {},
   "source": [
    "# 2. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8185c02",
   "metadata": {},
   "source": [
    "## 2.1 sentence piece 토크나이저 학습\n",
    "\n",
    "1. sentence piece 토크나이저는 비지도학습 토크나이저이므로 학습의 과정이 필요하다.\n",
    "2. vocab size는 위에서 언급한 것처럼 12000으로 잡을 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b62db2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.9/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7bec3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"naver_review.text\", 'w') as f:\n",
    "    for x in data.document:\n",
    "        f.write(x+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66c19534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=naver_review.text --model_prefix=naver_review_spm --vocab_size=12000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: naver_review.text\n",
      "  input_format: \n",
      "  model_prefix: naver_review_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 12000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: naver_review.text\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 163911 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=4143881\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1542\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 163911 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 264331 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 163911\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 248215\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 248215 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=129999 obj=13.6597 num_tokens=514454 num_tokens/piece=3.95737\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=119749 obj=12.7725 num_tokens=516651 num_tokens/piece=4.31445\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=89769 obj=12.8575 num_tokens=543660 num_tokens/piece=6.05621\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=89606 obj=12.8038 num_tokens=543915 num_tokens/piece=6.07007\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=67195 obj=13.0272 num_tokens=577559 num_tokens/piece=8.59527\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=67185 obj=12.9664 num_tokens=577713 num_tokens/piece=8.59884\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=50388 obj=13.212 num_tokens=609969 num_tokens/piece=12.1054\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=50388 obj=13.1517 num_tokens=609995 num_tokens/piece=12.106\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=37791 obj=13.4373 num_tokens=644157 num_tokens/piece=17.0452\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=37791 obj=13.3733 num_tokens=644180 num_tokens/piece=17.0459\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=28343 obj=13.6837 num_tokens=678732 num_tokens/piece=23.9471\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=28343 obj=13.6174 num_tokens=678743 num_tokens/piece=23.9475\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=21257 obj=13.9636 num_tokens=714399 num_tokens/piece=33.6077\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=21257 obj=13.8919 num_tokens=714518 num_tokens/piece=33.6133\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=15942 obj=14.2631 num_tokens=751380 num_tokens/piece=47.1321\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=15942 obj=14.1836 num_tokens=751396 num_tokens/piece=47.1331\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=13200 obj=14.4434 num_tokens=775931 num_tokens/piece=58.7827\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=13200 obj=14.3875 num_tokens=776101 num_tokens/piece=58.7955\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: naver_review_spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: naver_review_spm.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "vocab_size = 12000    \n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=naver_review_spm --vocab_size={}'.format(\"naver_review.text\", vocab_size)    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d73d776f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 458613 Feb 16 17:30 naver_review_spm.model\r\n",
      "-rw-r--r-- 1 root root 231738 Feb 16 17:30 naver_review_spm.vocab\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l naver_review_spm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ccf2f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = pd.read_csv('naver_review_spm.vocab', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c08b2d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁</td>\n",
       "      <td>-3.58923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>▁영화</td>\n",
       "      <td>-4.21357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>랐</td>\n",
       "      <td>-14.89490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>떻</td>\n",
       "      <td>-14.89500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>잊</td>\n",
       "      <td>-14.89510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>깊</td>\n",
       "      <td>-14.89520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>넋</td>\n",
       "      <td>-14.89520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0      <unk>   0.00000\n",
       "1        <s>   0.00000\n",
       "2       </s>   0.00000\n",
       "3          ▁  -3.58923\n",
       "4        ▁영화  -4.21357\n",
       "...      ...       ...\n",
       "11995      랐 -14.89490\n",
       "11996      떻 -14.89500\n",
       "11997      잊 -14.89510\n",
       "11998      깊 -14.89520\n",
       "11999      넋 -14.89520\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb5a72ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('naver_review_spm.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "434f505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize_pre(s, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./naver_review_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre')\n",
    "\n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3e89d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize_post(s, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./naver_review_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35809e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_tensor_pre, sp_word_index_pre, sp_index_word_pre = sp_tokenize_pre(s, data.document)\n",
    "sp_tensor_post,sp_word_index_post, sp_index_word_post = sp_tokenize_post(s, data.document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f14f63e",
   "metadata": {},
   "source": [
    "## 2.2 학습\n",
    "\n",
    "1. train : val : test = 0.5625 : 0.1875 : 0.25\n",
    "2. 임베딩 차원은 100\n",
    "3. lstm 차원은 128\n",
    "4. 각 토크나이저 별로 pre padding과 post padding의 성능 차이를 비교할 것이다.\n",
    "5. 따라서 4개의 토크나이저를 2개의 padding 별로 학습해야 해서 총 8번의 학습이 이뤄질 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d35bff6",
   "metadata": {},
   "source": [
    "### 2.2.1 mecab - pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "123dbaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(mecab_tensor_pre, \n",
    "                                                    mecab_data.label, \n",
    "                                                    test_size=0.25,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, \n",
    "                                                    y_train, \n",
    "                                                    test_size=0.25, \n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0aa11cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92199\n",
      "92199\n",
      "30734\n",
      "30734\n",
      "40978\n",
      "40978\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train),len(y_train),sep=\"\\n\")\n",
    "print(len(x_val),len(y_val),sep=\"\\n\")\n",
    "print(len(x_test),len(y_test),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65581774",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "inputs = keras.Input(shape=(None,))\n",
    "embedded = layers.Embedding(input_dim = vocab_size, \n",
    "                            output_dim = word_vector_dim)(inputs)\n",
    "x = layers.LSTM(128, return_sequences=True)(embedded)\n",
    "x = layers.LSTM(128)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "mecab_pre_model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afd16311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 100)         1200000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 128)         117248    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,448,961\n",
      "Trainable params: 1,448,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mecab_pre_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81d228cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab_pre_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "es = EarlyStopping(monitor='val_loss', \n",
    "                   mode='min', \n",
    "                   verbose=1, \n",
    "                   patience=4)\n",
    "\n",
    "mecab_pre_model_mc = ModelCheckpoint('/aiffel/aiffel/aiffel/mecab_pre_model.h5', \n",
    "                     monitor='val_accuracy', \n",
    "                     mode='max', \n",
    "                     verbose=1, \n",
    "                     save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a4baa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "181/181 [==============================] - 12s 27ms/step - loss: 0.4486 - accuracy: 0.7903 - val_loss: 0.3727 - val_accuracy: 0.8336\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.83357, saving model to /aiffel/aiffel/aiffel/mecab_pre_model.h5\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.3421 - accuracy: 0.8527 - val_loss: 0.3678 - val_accuracy: 0.8380\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.83357 to 0.83800, saving model to /aiffel/aiffel/aiffel/mecab_pre_model.h5\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.3167 - accuracy: 0.8646 - val_loss: 0.3643 - val_accuracy: 0.8431\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.83800 to 0.84314, saving model to /aiffel/aiffel/aiffel/mecab_pre_model.h5\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.2961 - accuracy: 0.8750 - val_loss: 0.3586 - val_accuracy: 0.8434\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.84314 to 0.84337, saving model to /aiffel/aiffel/aiffel/mecab_pre_model.h5\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.2767 - accuracy: 0.8838 - val_loss: 0.3526 - val_accuracy: 0.8548\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.84337 to 0.85479, saving model to /aiffel/aiffel/aiffel/mecab_pre_model.h5\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.2577 - accuracy: 0.8925 - val_loss: 0.3803 - val_accuracy: 0.8513\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.85479\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.2398 - accuracy: 0.9005 - val_loss: 0.3789 - val_accuracy: 0.8541\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.85479\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.2233 - accuracy: 0.9082 - val_loss: 0.3800 - val_accuracy: 0.8477\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.85479\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.2074 - accuracy: 0.9159 - val_loss: 0.4004 - val_accuracy: 0.8441\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.85479\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "history =mecab_pre_model.fit(x_train,\n",
    "                             y_train, \n",
    "                             epochs=epochs, \n",
    "                             batch_size=512, \n",
    "                             validation_data=(x_val, y_val),\n",
    "                             callbacks=[es, mecab_pre_model_mc],\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "242337b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281/1281 [==============================] - 7s 4ms/step - loss: 0.3546 - accuracy: 0.8502\n",
      "테스트 정확도: 0.8501878976821899\n"
     ]
    }
   ],
   "source": [
    "mecab_pre_loaded_model = load_model('/aiffel/aiffel/aiffel/mecab_pre_model.h5')\n",
    "print(\"테스트 정확도: {}\".format(mecab_pre_loaded_model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02a524c",
   "metadata": {},
   "source": [
    "### 2.2.2 mecab - post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b8d9f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(mecab_tensor_post, \n",
    "                                                    mecab_data.label, \n",
    "                                                    test_size=0.25,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, \n",
    "                                                    y_train, \n",
    "                                                    test_size=0.25, \n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0497ebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92199\n",
      "92199\n",
      "30734\n",
      "30734\n",
      "40978\n",
      "40978\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train),len(y_train),sep=\"\\n\")\n",
    "print(len(x_val),len(y_val),sep=\"\\n\")\n",
    "print(len(x_test),len(y_test),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "293b1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "inputs = keras.Input(shape=(None,))\n",
    "embedded = layers.Embedding(input_dim = vocab_size, \n",
    "                            output_dim = word_vector_dim)(inputs)\n",
    "x = layers.LSTM(128, return_sequences=True)(embedded)\n",
    "x = layers.LSTM(128)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "mecab_post_model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "253af2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 100)         1200000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 128)         117248    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,448,961\n",
      "Trainable params: 1,448,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mecab_post_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b1be21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab_post_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "es = EarlyStopping(monitor='val_loss', \n",
    "                   mode='min', \n",
    "                   verbose=1, \n",
    "                   patience=4)\n",
    "\n",
    "mecab_post_model_mc = ModelCheckpoint('/aiffel/aiffel/aiffel/mecab_post_model.h5', \n",
    "                     monitor='val_accuracy', \n",
    "                     mode='max', \n",
    "                     verbose=1, \n",
    "                     save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bc44cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "181/181 [==============================] - 10s 27ms/step - loss: 0.4391 - accuracy: 0.7926 - val_loss: 0.4019 - val_accuracy: 0.8232\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82323, saving model to /aiffel/aiffel/aiffel/mecab_post_model.h5\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.3438 - accuracy: 0.8526 - val_loss: 0.3828 - val_accuracy: 0.8344\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.82323 to 0.83439, saving model to /aiffel/aiffel/aiffel/mecab_post_model.h5\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.3178 - accuracy: 0.8653 - val_loss: 0.3685 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.83439 to 0.84463, saving model to /aiffel/aiffel/aiffel/mecab_post_model.h5\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.2961 - accuracy: 0.8745 - val_loss: 0.3614 - val_accuracy: 0.8481\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.84463 to 0.84808, saving model to /aiffel/aiffel/aiffel/mecab_post_model.h5\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.2764 - accuracy: 0.8837 - val_loss: 0.3877 - val_accuracy: 0.8504\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.84808 to 0.85039, saving model to /aiffel/aiffel/aiffel/mecab_post_model.h5\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.2583 - accuracy: 0.8935 - val_loss: 0.3399 - val_accuracy: 0.8530\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.85039 to 0.85303, saving model to /aiffel/aiffel/aiffel/mecab_post_model.h5\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - 4s 19ms/step - loss: 0.2417 - accuracy: 0.9012 - val_loss: 0.3667 - val_accuracy: 0.8522\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.85303\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - 4s 19ms/step - loss: 0.2252 - accuracy: 0.9089 - val_loss: 0.3799 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.85303\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - 4s 19ms/step - loss: 0.2096 - accuracy: 0.9171 - val_loss: 0.3941 - val_accuracy: 0.8517\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.85303\n",
      "Epoch 10/50\n",
      "181/181 [==============================] - 4s 19ms/step - loss: 0.1949 - accuracy: 0.9234 - val_loss: 0.4214 - val_accuracy: 0.8399\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.85303\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "history =mecab_post_model.fit(x_train,\n",
    "                             y_train, \n",
    "                             epochs=epochs, \n",
    "                             batch_size=512, \n",
    "                             validation_data=(x_val, y_val),\n",
    "                             callbacks=[es, mecab_post_model_mc],\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da2942fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281/1281 [==============================] - 6s 4ms/step - loss: 0.3412 - accuracy: 0.8520\n",
      "테스트 정확도: 0.85199373960495\n"
     ]
    }
   ],
   "source": [
    "mecab_post_loaded_model = load_model('/aiffel/aiffel/aiffel/mecab_post_model.h5')\n",
    "print(\"테스트 정확도: {}\".format(mecab_post_loaded_model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d8426f",
   "metadata": {},
   "source": [
    "### 2.2.3 komoran - pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8c2e4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(komoran_tensor_pre, \n",
    "                                                    komoran_data.label, \n",
    "                                                    test_size=0.25,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, \n",
    "                                                    y_train, \n",
    "                                                    test_size=0.25, \n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a9c9544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92199\n",
      "92199\n",
      "30734\n",
      "30734\n",
      "40978\n",
      "40978\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train),len(y_train),sep=\"\\n\")\n",
    "print(len(x_val),len(y_val),sep=\"\\n\")\n",
    "print(len(x_test),len(y_test),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e69169e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "inputs = keras.Input(shape=(None,))\n",
    "embedded = layers.Embedding(input_dim = vocab_size, \n",
    "                            output_dim = word_vector_dim)(inputs)\n",
    "x = layers.LSTM(128, return_sequences=True)(embedded)\n",
    "x = layers.LSTM(128)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "komoran_pre_model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "944da37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 100)         1200000   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, None, 128)         117248    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,448,961\n",
      "Trainable params: 1,448,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "komoran_pre_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f66a6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran_pre_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "es = EarlyStopping(monitor='val_loss', \n",
    "                   mode='min', \n",
    "                   verbose=1, \n",
    "                   patience=4)\n",
    "\n",
    "komoran_pre_model_mc = ModelCheckpoint('/aiffel/aiffel/aiffel/komoran_pre_model.h5', \n",
    "                     monitor='val_accuracy', \n",
    "                     mode='max', \n",
    "                     verbose=1, \n",
    "                     save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "48473faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "181/181 [==============================] - 15s 41ms/step - loss: 0.4649 - accuracy: 0.7824 - val_loss: 0.3823 - val_accuracy: 0.8298\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82977, saving model to /aiffel/aiffel/aiffel/komoran_pre_model.h5\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - 4s 22ms/step - loss: 0.3574 - accuracy: 0.8446 - val_loss: 0.3826 - val_accuracy: 0.8306\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.82977 to 0.83064, saving model to /aiffel/aiffel/aiffel/komoran_pre_model.h5\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - 4s 22ms/step - loss: 0.3340 - accuracy: 0.8555 - val_loss: 0.3792 - val_accuracy: 0.8388\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.83064 to 0.83878, saving model to /aiffel/aiffel/aiffel/komoran_pre_model.h5\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - 4s 22ms/step - loss: 0.3133 - accuracy: 0.8657 - val_loss: 0.3478 - val_accuracy: 0.8441\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.83878 to 0.84411, saving model to /aiffel/aiffel/aiffel/komoran_pre_model.h5\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - 4s 22ms/step - loss: 0.2923 - accuracy: 0.8764 - val_loss: 0.3869 - val_accuracy: 0.8442\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.84411 to 0.84418, saving model to /aiffel/aiffel/aiffel/komoran_pre_model.h5\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - 4s 23ms/step - loss: 0.2747 - accuracy: 0.8842 - val_loss: 0.3584 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.84418 to 0.84662, saving model to /aiffel/aiffel/aiffel/komoran_pre_model.h5\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - 4s 23ms/step - loss: 0.2579 - accuracy: 0.8928 - val_loss: 0.4013 - val_accuracy: 0.8355\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.84662\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - 4s 22ms/step - loss: 0.2424 - accuracy: 0.9008 - val_loss: 0.4090 - val_accuracy: 0.8347\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.84662\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "history =komoran_pre_model.fit(x_train,\n",
    "                             y_train, \n",
    "                             epochs=epochs, \n",
    "                             batch_size=512, \n",
    "                             validation_data=(x_val, y_val),\n",
    "                             callbacks=[es, komoran_pre_model_mc],\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "31dc0b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281/1281 [==============================] - 6s 4ms/step - loss: 0.3611 - accuracy: 0.8461\n",
      "테스트 정확도: 0.8460637331008911\n"
     ]
    }
   ],
   "source": [
    "komoran_pre_loaded_model = load_model('/aiffel/aiffel/aiffel/komoran_pre_model.h5')\n",
    "print(\"테스트 정확도: {}\".format(komoran_pre_loaded_model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4371aff",
   "metadata": {},
   "source": [
    "### 2.2.4 komoran - post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6a28bd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(komoran_tensor_post, \n",
    "                                                    komoran_data.label, \n",
    "                                                    test_size=0.25,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, \n",
    "                                                    y_train, \n",
    "                                                    test_size=0.25, \n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9ed7fd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92199\n",
      "92199\n",
      "30734\n",
      "30734\n",
      "40978\n",
      "40978\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train),len(y_train),sep=\"\\n\")\n",
    "print(len(x_val),len(y_val),sep=\"\\n\")\n",
    "print(len(x_test),len(y_test),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9df05046",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "inputs = keras.Input(shape=(None,))\n",
    "embedded = layers.Embedding(input_dim = vocab_size, \n",
    "                            output_dim = word_vector_dim)(inputs)\n",
    "x = layers.LSTM(128, return_sequences=True)(embedded)\n",
    "x = layers.LSTM(128)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "komoran_post_model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "31eb0998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, None, 100)         1200000   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, None, 128)         117248    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,448,961\n",
      "Trainable params: 1,448,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "komoran_post_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b78a4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran_post_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "es = EarlyStopping(monitor='val_loss', \n",
    "                   mode='min', \n",
    "                   verbose=1, \n",
    "                   patience=4)\n",
    "\n",
    "komoran_post_model_mc = ModelCheckpoint('/aiffel/aiffel/aiffel/komoran_post_model.h5', \n",
    "                     monitor='val_accuracy', \n",
    "                     mode='max', \n",
    "                     verbose=1, \n",
    "                     save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "869ff874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "181/181 [==============================] - 12s 31ms/step - loss: 0.4507 - accuracy: 0.7850 - val_loss: 0.3988 - val_accuracy: 0.8307\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.83071, saving model to /aiffel/aiffel/aiffel/komoran_post_model.h5\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - 4s 23ms/step - loss: 0.3619 - accuracy: 0.8412 - val_loss: 0.3841 - val_accuracy: 0.8272\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.83071\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - 4s 23ms/step - loss: 0.3341 - accuracy: 0.8550 - val_loss: 0.4309 - val_accuracy: 0.8236\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.83071\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - 4s 23ms/step - loss: 0.3138 - accuracy: 0.8645 - val_loss: 0.3660 - val_accuracy: 0.8360\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.83071 to 0.83598, saving model to /aiffel/aiffel/aiffel/komoran_post_model.h5\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - 4s 23ms/step - loss: 0.2931 - accuracy: 0.8753 - val_loss: 0.3457 - val_accuracy: 0.8454\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.83598 to 0.84538, saving model to /aiffel/aiffel/aiffel/komoran_post_model.h5\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - 4s 23ms/step - loss: 0.2748 - accuracy: 0.8842 - val_loss: 0.3931 - val_accuracy: 0.8463\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.84538 to 0.84633, saving model to /aiffel/aiffel/aiffel/komoran_post_model.h5\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - 4s 23ms/step - loss: 0.2579 - accuracy: 0.8924 - val_loss: 0.4316 - val_accuracy: 0.8311\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.84633\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - 4s 23ms/step - loss: 0.2425 - accuracy: 0.8994 - val_loss: 0.4086 - val_accuracy: 0.8377\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.84633\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - 4s 23ms/step - loss: 0.2276 - accuracy: 0.9068 - val_loss: 0.4009 - val_accuracy: 0.8459\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.84633\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "history =komoran_post_model.fit(x_train,\n",
    "                             y_train, \n",
    "                             epochs=epochs, \n",
    "                             batch_size=512, \n",
    "                             validation_data=(x_val, y_val),\n",
    "                             callbacks=[es, komoran_post_model_mc],\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5019fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281/1281 [==============================] - 6s 4ms/step - loss: 0.3904 - accuracy: 0.8462\n",
      "테스트 정확도: 0.8461613655090332\n"
     ]
    }
   ],
   "source": [
    "komoran_post_loaded_model = load_model('/aiffel/aiffel/aiffel/komoran_post_model.h5')\n",
    "print(\"테스트 정확도: {}\".format(komoran_post_loaded_model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96715f26",
   "metadata": {},
   "source": [
    "### 2.2.5 hannanum - pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "309b28c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(hannanum_tensor_pre, \n",
    "                                                    hannanum_data.label, \n",
    "                                                    test_size=0.25,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, \n",
    "                                                    y_train, \n",
    "                                                    test_size=0.25, \n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4b1ba5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92199\n",
      "92199\n",
      "30734\n",
      "30734\n",
      "40978\n",
      "40978\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train),len(y_train),sep=\"\\n\")\n",
    "print(len(x_val),len(y_val),sep=\"\\n\")\n",
    "print(len(x_test),len(y_test),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10f56d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "inputs = keras.Input(shape=(None,))\n",
    "embedded = layers.Embedding(input_dim = vocab_size, \n",
    "                            output_dim = word_vector_dim)(inputs)\n",
    "x = layers.LSTM(128, return_sequences=True)(embedded)\n",
    "x = layers.LSTM(128)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "hannanum_pre_model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9121e7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, None, 100)         1200000   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, None, 128)         117248    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,448,961\n",
      "Trainable params: 1,448,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hannanum_pre_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9b5e13ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hannanum_pre_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "es = EarlyStopping(monitor='val_loss', \n",
    "                   mode='min', \n",
    "                   verbose=1, \n",
    "                   patience=4)\n",
    "\n",
    "hannanum_pre_model_mc = ModelCheckpoint('/aiffel/aiffel/aiffel/hannanum_pre_model.h5', \n",
    "                     monitor='val_accuracy', \n",
    "                     mode='max', \n",
    "                     verbose=1, \n",
    "                     save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5feca3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "181/181 [==============================] - 10s 29ms/step - loss: 0.4992 - accuracy: 0.7451 - val_loss: 0.4361 - val_accuracy: 0.7872\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78724, saving model to /aiffel/aiffel/aiffel/hannanum_pre_model.h5\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.4016 - accuracy: 0.8123 - val_loss: 0.4195 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.78724 to 0.80312, saving model to /aiffel/aiffel/aiffel/hannanum_pre_model.h5\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.3788 - accuracy: 0.8241 - val_loss: 0.4280 - val_accuracy: 0.7949\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.80312\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.3618 - accuracy: 0.8327 - val_loss: 0.4066 - val_accuracy: 0.8056\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.80312 to 0.80559, saving model to /aiffel/aiffel/aiffel/hannanum_pre_model.h5\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.3474 - accuracy: 0.8395 - val_loss: 0.4086 - val_accuracy: 0.8093\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.80559 to 0.80933, saving model to /aiffel/aiffel/aiffel/hannanum_pre_model.h5\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.3338 - accuracy: 0.8464 - val_loss: 0.4011 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.80933 to 0.81197, saving model to /aiffel/aiffel/aiffel/hannanum_pre_model.h5\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.3209 - accuracy: 0.8519 - val_loss: 0.4291 - val_accuracy: 0.8140\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.81197 to 0.81405, saving model to /aiffel/aiffel/aiffel/hannanum_pre_model.h5\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.3079 - accuracy: 0.8595 - val_loss: 0.4387 - val_accuracy: 0.8059\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.81405\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.2960 - accuracy: 0.8648 - val_loss: 0.4831 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.81405\n",
      "Epoch 10/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.2839 - accuracy: 0.8705 - val_loss: 0.4430 - val_accuracy: 0.7952\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.81405\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "history =hannanum_pre_model.fit(x_train,\n",
    "                             y_train, \n",
    "                             epochs=epochs, \n",
    "                             batch_size=512, \n",
    "                             validation_data=(x_val, y_val),\n",
    "                             callbacks=[es, hannanum_pre_model_mc],\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e3b23874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281/1281 [==============================] - 5s 4ms/step - loss: 0.4401 - accuracy: 0.8104\n",
      "테스트 정확도: 0.8103616833686829\n"
     ]
    }
   ],
   "source": [
    "hannanum_pre_loaded_model = load_model('/aiffel/aiffel/aiffel/hannanum_pre_model.h5')\n",
    "print(\"테스트 정확도: {}\".format(hannanum_pre_loaded_model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13559ae1",
   "metadata": {},
   "source": [
    "### 2.2.6 hannanum - post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "277cf7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(hannanum_tensor_post, \n",
    "                                                    hannanum_data.label, \n",
    "                                                    test_size=0.25,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, \n",
    "                                                    y_train, \n",
    "                                                    test_size=0.25, \n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "55fd9bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92199\n",
      "92199\n",
      "30734\n",
      "30734\n",
      "40978\n",
      "40978\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train),len(y_train),sep=\"\\n\")\n",
    "print(len(x_val),len(y_val),sep=\"\\n\")\n",
    "print(len(x_test),len(y_test),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5522628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "inputs = keras.Input(shape=(None,))\n",
    "embedded = layers.Embedding(input_dim = vocab_size, \n",
    "                            output_dim = word_vector_dim)(inputs)\n",
    "x = layers.LSTM(128, return_sequences=True)(embedded)\n",
    "x = layers.LSTM(128)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "hannanum_post_model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c5d559bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, None, 100)         1200000   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, None, 128)         117248    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,448,961\n",
      "Trainable params: 1,448,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hannanum_post_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "337458ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "hannanum_post_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "es = EarlyStopping(monitor='val_loss', \n",
    "                   mode='min', \n",
    "                   verbose=1, \n",
    "                   patience=4)\n",
    "\n",
    "hannanum_post_model_mc = ModelCheckpoint('/aiffel/aiffel/aiffel/hannanum_post_model.h5', \n",
    "                     monitor='val_accuracy', \n",
    "                     mode='max', \n",
    "                     verbose=1, \n",
    "                     save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8873d0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "181/181 [==============================] - 11s 30ms/step - loss: 0.4975 - accuracy: 0.7475 - val_loss: 0.4315 - val_accuracy: 0.7950\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79498, saving model to /aiffel/aiffel/aiffel/hannanum_post_model.h5\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.3993 - accuracy: 0.8143 - val_loss: 0.4393 - val_accuracy: 0.7904\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.79498\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.3762 - accuracy: 0.8255 - val_loss: 0.4140 - val_accuracy: 0.8059\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.79498 to 0.80592, saving model to /aiffel/aiffel/aiffel/hannanum_post_model.h5\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.3600 - accuracy: 0.8343 - val_loss: 0.4080 - val_accuracy: 0.8042\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.80592\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.3462 - accuracy: 0.8402 - val_loss: 0.4087 - val_accuracy: 0.8060\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.80592 to 0.80605, saving model to /aiffel/aiffel/aiffel/hannanum_post_model.h5\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.3328 - accuracy: 0.8476 - val_loss: 0.4021 - val_accuracy: 0.8087\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.80605 to 0.80871, saving model to /aiffel/aiffel/aiffel/hannanum_post_model.h5\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - 4s 22ms/step - loss: 0.3190 - accuracy: 0.8529 - val_loss: 0.4244 - val_accuracy: 0.8086\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.80871\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - 4s 22ms/step - loss: 0.3053 - accuracy: 0.8587 - val_loss: 0.4460 - val_accuracy: 0.8024\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.80871\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.2912 - accuracy: 0.8669 - val_loss: 0.4415 - val_accuracy: 0.8033\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.80871\n",
      "Epoch 10/50\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 0.2777 - accuracy: 0.8734 - val_loss: 0.4533 - val_accuracy: 0.7936\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80871\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "history =hannanum_post_model.fit(x_train,\n",
    "                             y_train, \n",
    "                             epochs=epochs, \n",
    "                             batch_size=512, \n",
    "                             validation_data=(x_val, y_val),\n",
    "                             callbacks=[es, hannanum_post_model_mc],\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a55f88a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281/1281 [==============================] - 6s 4ms/step - loss: 0.4008 - accuracy: 0.8087\n",
      "테스트 정확도: 0.8086778521537781\n"
     ]
    }
   ],
   "source": [
    "hannanum_post_loaded_model = load_model('/aiffel/aiffel/aiffel/hannanum_post_model.h5')\n",
    "print(\"테스트 정확도: {}\".format(hannanum_post_loaded_model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a56814",
   "metadata": {},
   "source": [
    "### 2.2.7 Sentencepiece - pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cc3f15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sp_tensor_pre, \n",
    "                                                    data.label, \n",
    "                                                    test_size=0.25,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, \n",
    "                                                    y_train, \n",
    "                                                    test_size=0.25, \n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7c74b197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92199\n",
      "92199\n",
      "30734\n",
      "30734\n",
      "40978\n",
      "40978\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train),len(y_train),sep=\"\\n\")\n",
    "print(len(x_val),len(y_val),sep=\"\\n\")\n",
    "print(len(x_test),len(y_test),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c74ee206",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "inputs = keras.Input(shape=(None,))\n",
    "embedded = layers.Embedding(input_dim = vocab_size, \n",
    "                            output_dim = word_vector_dim)(inputs)\n",
    "x = layers.LSTM(128, return_sequences=True)(embedded)\n",
    "x = layers.LSTM(128)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "sp_pre_model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c2bfebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, None, 100)         1200000   \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, None, 128)         117248    \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,448,961\n",
      "Trainable params: 1,448,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sp_pre_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d9431e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_pre_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "es = EarlyStopping(monitor='val_loss', \n",
    "                   mode='min', \n",
    "                   verbose=1, \n",
    "                   patience=4)\n",
    "\n",
    "sp_pre_model_mc = ModelCheckpoint('/aiffel/aiffel/aiffel/sp_pre_model.h5', \n",
    "                     monitor='val_accuracy', \n",
    "                     mode='max', \n",
    "                     verbose=1, \n",
    "                     save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "11b8b5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "181/181 [==============================] - 14s 38ms/step - loss: 0.4611 - accuracy: 0.7831 - val_loss: 0.3896 - val_accuracy: 0.8212\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82124, saving model to /aiffel/aiffel/aiffel/sp_pre_model.h5\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - 4s 23ms/step - loss: 0.3351 - accuracy: 0.8565 - val_loss: 0.3518 - val_accuracy: 0.8451\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.82124 to 0.84506, saving model to /aiffel/aiffel/aiffel/sp_pre_model.h5\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - 4s 23ms/step - loss: 0.3065 - accuracy: 0.8696 - val_loss: 0.3745 - val_accuracy: 0.8445\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.84506\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - 4s 24ms/step - loss: 0.2878 - accuracy: 0.8788 - val_loss: 0.3553 - val_accuracy: 0.8486\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.84506 to 0.84864, saving model to /aiffel/aiffel/aiffel/sp_pre_model.h5\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - 4s 24ms/step - loss: 0.2669 - accuracy: 0.8879 - val_loss: 0.3463 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.84864\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - 4s 24ms/step - loss: 0.2442 - accuracy: 0.8987 - val_loss: 0.4119 - val_accuracy: 0.8489\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.84864 to 0.84886, saving model to /aiffel/aiffel/aiffel/sp_pre_model.h5\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - 4s 24ms/step - loss: 0.2186 - accuracy: 0.9100 - val_loss: 0.4269 - val_accuracy: 0.8380\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.84886\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - 4s 24ms/step - loss: 0.1938 - accuracy: 0.9212 - val_loss: 0.3964 - val_accuracy: 0.8370\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.84886\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - 4s 24ms/step - loss: 0.1712 - accuracy: 0.9308 - val_loss: 0.4351 - val_accuracy: 0.8242\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.84886\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "history =sp_pre_model.fit(x_train,\n",
    "                             y_train, \n",
    "                             epochs=epochs, \n",
    "                             batch_size=512, \n",
    "                             validation_data=(x_val, y_val),\n",
    "                             callbacks=[es, sp_pre_model_mc],\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5227514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281/1281 [==============================] - 6s 4ms/step - loss: 0.4230 - accuracy: 0.8449\n",
      "테스트 정확도: 0.8449411988258362\n"
     ]
    }
   ],
   "source": [
    "sp_pre_loaded_model = load_model('/aiffel/aiffel/aiffel/sp_pre_model.h5')\n",
    "print(\"테스트 정확도: {}\".format(sp_pre_loaded_model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b897b5",
   "metadata": {},
   "source": [
    "### 2.2.8 Sentencepiece - post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "395d3f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sp_tensor_post, \n",
    "                                                    data.label, \n",
    "                                                    test_size=0.25,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, \n",
    "                                                    y_train, \n",
    "                                                    test_size=0.25, \n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "78f22f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92199\n",
      "92199\n",
      "30734\n",
      "30734\n",
      "40978\n",
      "40978\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train),len(y_train),sep=\"\\n\")\n",
    "print(len(x_val),len(y_val),sep=\"\\n\")\n",
    "print(len(x_test),len(y_test),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7db2a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "inputs = keras.Input(shape=(None,))\n",
    "embedded = layers.Embedding(input_dim = vocab_size, \n",
    "                            output_dim = word_vector_dim)(inputs)\n",
    "x = layers.LSTM(128, return_sequences=True)(embedded)\n",
    "x = layers.LSTM(128)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "sp_post_model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4526f8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, None, 100)         1200000   \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, None, 128)         117248    \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,448,961\n",
      "Trainable params: 1,448,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sp_post_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d3ee90ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_post_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "es = EarlyStopping(monitor='val_loss', \n",
    "                   mode='min', \n",
    "                   verbose=1, \n",
    "                   patience=4)\n",
    "\n",
    "sp_post_model_mc = ModelCheckpoint('/aiffel/aiffel/aiffel/sp_post_model.h5', \n",
    "                     monitor='val_accuracy', \n",
    "                     mode='max', \n",
    "                     verbose=1, \n",
    "                     save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2deacfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "181/181 [==============================] - 14s 33ms/step - loss: 0.5895 - accuracy: 0.6603 - val_loss: 0.4008 - val_accuracy: 0.8265\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82651, saving model to /aiffel/aiffel/aiffel/sp_post_model.h5\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - 4s 24ms/step - loss: 0.3862 - accuracy: 0.8378 - val_loss: 0.3997 - val_accuracy: 0.8185\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.82651\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - 4s 24ms/step - loss: 0.3446 - accuracy: 0.8570 - val_loss: 0.3841 - val_accuracy: 0.8233\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.82651\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - 4s 24ms/step - loss: 0.3198 - accuracy: 0.8675 - val_loss: 0.3718 - val_accuracy: 0.8433\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.82651 to 0.84330, saving model to /aiffel/aiffel/aiffel/sp_post_model.h5\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - 4s 24ms/step - loss: 0.3007 - accuracy: 0.8749 - val_loss: 0.4140 - val_accuracy: 0.8425\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.84330\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - 4s 24ms/step - loss: 0.2860 - accuracy: 0.8812 - val_loss: 0.4242 - val_accuracy: 0.8426\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.84330\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - 4s 25ms/step - loss: 0.2683 - accuracy: 0.8886 - val_loss: 0.3822 - val_accuracy: 0.8330\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.84330\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - 4s 25ms/step - loss: 0.2498 - accuracy: 0.8964 - val_loss: 0.4334 - val_accuracy: 0.8246\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.84330\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "history =sp_post_model.fit(x_train,\n",
    "                             y_train, \n",
    "                             epochs=epochs, \n",
    "                             batch_size=512, \n",
    "                             validation_data=(x_val, y_val),\n",
    "                             callbacks=[es, sp_post_model_mc],\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f6190ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281/1281 [==============================] - 7s 4ms/step - loss: 0.3720 - accuracy: 0.8458\n",
      "테스트 정확도: 0.8458440899848938\n"
     ]
    }
   ],
   "source": [
    "sp_post_loaded_model = load_model('/aiffel/aiffel/aiffel/sp_post_model.h5')\n",
    "print(\"테스트 정확도: {}\".format(sp_post_loaded_model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4db22",
   "metadata": {},
   "source": [
    "# 3. 결과 분석\n",
    "\n",
    "1. pre와 post 패딩의 유의미한 차이는 보이지 않았다.\n",
    "\n",
    "2. Hannanum은 80%의 accuracy, 나머지는 83~84%의 accuracy를 보였다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
