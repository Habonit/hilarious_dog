{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "819ba740",
   "metadata": {},
   "source": [
    "# 3. 프로젝트 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dc38c662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import glob  \n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "02bbf3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['', '', '[Spoken Intro:]', 'You ever want something ', \"that you know you shouldn't have \", \"The more you know you shouldn't have it, \", 'The more you want it ', 'And then one day you get it, ', \"It's so good too \", \"But it's just like my girl \", \"When she's around me \", 'I just feel so good, so good ', 'But right now I just feel cold, so cold ', 'Right down to my bones ', \"'Cause ooh... \", \"Ain't no sunshine when she's gone \", \"It's not warm when she's away \", \"Ain't no sunshine when she's gone \", \"And she's always gone too long \", 'Anytime she goes away ', '', \"Wonder this time where she's gone \", \"Wonder if she's gone to stay \", \"Ain't no sunshine when she's gone \", \"And this house just ain't no home \", 'Anytime she goes away ', '', 'I know, I know, I know, I know, ', 'I know, know, know, know, know, ', 'I know, I know, ', 'Hey I ought to leave ', 'I ought to leave her alone ', \"Ain't no sunshine when she's gone \", '', \"Ain't no sunshine when she's gone \", 'Only darkness every day ', \"Ain't no sunshine when she's gone \", \"And this house just ain't no home \", 'Anytime she goes away', '', '', 'Can it be I stayed away too long', 'Did I leave your mind when I was gone', \"It's not my thing trying to get back\", \"But this time let me tell you where I'm at\", \"You don't have to worry 'cause I'm coming\", 'Back to where I should have always stayed', \"And now I've heard the maybe to your story\", \"And it's enough love for me to stay\", '', 'Can it be I stayed away too long', 'Did I leave your mind when I was gone', \"It's not my thing trying to get back\", \"But this time let me tell you where I'm at\", '', '[Chorus:]', 'I wanna, wanna be where you are', 'Anywhere you are', 'I wanna, wanna be where you are', 'Everywhere you are', '', '[Bridge:]', \"Please don't close the door to our future\", \"There's so many things we haven't tried\", 'I could love you better than I used to', 'And give you all the love I have inside', '', '[Chorus:]', 'I wanna, wanna be where you are', 'Any, any, anywhere you are', 'I wanna, wanna be where you are', 'I gotta be where you are', '', '', 'Oooh', \"Foolish of me, I couldn't see \", 'The forest for the trees ', \"You've been so true \", \"I've been so cruel to you \", \"Oh, girl please don't leave me\", '', '[Chorus:]', \"If you stay I'll find a way \", 'To erase the past ', \"Baby don't leave me \", \"Girl don't take your love from me \", 'Oh girl ', '', 'What can I say to make you stay ', \"Baby, don't leave me \", \"You've been so kind \", 'It blows my mind to know', 'Oh girl, I really hurt you ', '', '[Chorus:]', \"Tell me girl, it's not to late \", 'And you give me a chance ', 'To make it up to you ', \"Don't take your love from me \", \"Girl don't take your love \"]\n"
     ]
    }
   ],
   "source": [
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path) \n",
    "\n",
    "raw_corpus = [] \n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines() \n",
    "        raw_corpus.extend(raw)\n",
    "        \n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "db929aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r'[^a-zA-Z?.!,¿]+', \" \",sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = '<start> ' + sentence + ' <end>'\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2c8b4379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '[Spoken Intro:]',\n",
       " 'You ever want something ',\n",
       " \"that you know you shouldn't have \",\n",
       " \"The more you know you shouldn't have it, \",\n",
       " 'The more you want it ',\n",
       " 'And then one day you get it, ',\n",
       " \"It's so good too \",\n",
       " \"But it's just like my girl \",\n",
       " \"When she's around me \",\n",
       " 'I just feel so good, so good ',\n",
       " 'But right now I just feel cold, so cold ',\n",
       " 'Right down to my bones ',\n",
       " \"'Cause ooh... \",\n",
       " \"Ain't no sunshine when she's gone \",\n",
       " \"It's not warm when she's away \",\n",
       " \"Ain't no sunshine when she's gone \",\n",
       " \"And she's always gone too long \",\n",
       " 'Anytime she goes away ',\n",
       " '',\n",
       " \"Wonder this time where she's gone \",\n",
       " \"Wonder if she's gone to stay \",\n",
       " \"Ain't no sunshine when she's gone \",\n",
       " \"And this house just ain't no home \",\n",
       " 'Anytime she goes away ',\n",
       " '',\n",
       " 'I know, I know, I know, I know, ',\n",
       " 'I know, know, know, know, know, ',\n",
       " 'I know, I know, ',\n",
       " 'Hey I ought to leave ',\n",
       " 'I ought to leave her alone ',\n",
       " \"Ain't no sunshine when she's gone \",\n",
       " '',\n",
       " \"Ain't no sunshine when she's gone \",\n",
       " 'Only darkness every day ',\n",
       " \"Ain't no sunshine when she's gone \",\n",
       " \"And this house just ain't no home \",\n",
       " 'Anytime she goes away',\n",
       " '',\n",
       " '',\n",
       " 'Can it be I stayed away too long',\n",
       " 'Did I leave your mind when I was gone',\n",
       " \"It's not my thing trying to get back\",\n",
       " \"But this time let me tell you where I'm at\",\n",
       " \"You don't have to worry 'cause I'm coming\",\n",
       " 'Back to where I should have always stayed',\n",
       " \"And now I've heard the maybe to your story\",\n",
       " \"And it's enough love for me to stay\",\n",
       " '',\n",
       " 'Can it be I stayed away too long',\n",
       " 'Did I leave your mind when I was gone',\n",
       " \"It's not my thing trying to get back\",\n",
       " \"But this time let me tell you where I'm at\",\n",
       " '',\n",
       " '[Chorus:]',\n",
       " 'I wanna, wanna be where you are',\n",
       " 'Anywhere you are',\n",
       " 'I wanna, wanna be where you are',\n",
       " 'Everywhere you are',\n",
       " '',\n",
       " '[Bridge:]',\n",
       " \"Please don't close the door to our future\",\n",
       " \"There's so many things we haven't tried\",\n",
       " 'I could love you better than I used to',\n",
       " 'And give you all the love I have inside',\n",
       " '',\n",
       " '[Chorus:]',\n",
       " 'I wanna, wanna be where you are',\n",
       " 'Any, any, anywhere you are',\n",
       " 'I wanna, wanna be where you are',\n",
       " 'I gotta be where you are',\n",
       " '',\n",
       " '',\n",
       " 'Oooh',\n",
       " \"Foolish of me, I couldn't see \",\n",
       " 'The forest for the trees ',\n",
       " \"You've been so true \",\n",
       " \"I've been so cruel to you \",\n",
       " \"Oh, girl please don't leave me\",\n",
       " '',\n",
       " '[Chorus:]',\n",
       " \"If you stay I'll find a way \",\n",
       " 'To erase the past ',\n",
       " \"Baby don't leave me \",\n",
       " \"Girl don't take your love from me \",\n",
       " 'Oh girl ',\n",
       " '',\n",
       " 'What can I say to make you stay ',\n",
       " \"Baby, don't leave me \",\n",
       " \"You've been so kind \",\n",
       " 'It blows my mind to know',\n",
       " 'Oh girl, I really hurt you ',\n",
       " '',\n",
       " '[Chorus:]',\n",
       " \"Tell me girl, it's not to late \",\n",
       " 'And you give me a chance ',\n",
       " 'To make it up to you ',\n",
       " \"Don't take your love from me \",\n",
       " \"Girl don't take your love \"]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_corpus[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "55bff484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175749 ['<start> spoken intro <end>', '<start> you ever want something <end>', '<start> that you know you shouldn t have <end>']\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence)  == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "    \n",
    "print(len(corpus), corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a3d98805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156013 ['<start> spoken intro <end>', '<start> you ever want something <end>', '<start> that you know you shouldn t have <end>']\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence)  == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    if len(preprocessed_sentence.split()) <= 15:\n",
    "        corpus.append(preprocessed_sentence)\n",
    "    \n",
    "print(len(corpus), corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5619f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=12000, \n",
    "    filters=' ', \n",
    "    oov_token='<unk>'\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "28aa40de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    \n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "761606aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_test_split(corpus, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4120ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "60ae32cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor = tokenize(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d170fb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124810, 15)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cb536308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31203, 15)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1cd4117a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124810, 15)\n",
      "(124810, 14)\n",
      "(124810, 14)\n"
     ]
    }
   ],
   "source": [
    "print(x_tensor.shape)\n",
    "x_src_input = x_tensor[:, :-1]  \n",
    "print(x_tensor[:,:-1].shape)\n",
    "x_tgt_input = x_tensor[:, 1:]\n",
    "print(x_tensor[:,1:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4a0a2938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31203, 15)\n",
      "(31203, 14)\n",
      "(31203, 14)\n"
     ]
    }
   ],
   "source": [
    "print(y_tensor.shape)\n",
    "y_src_input = y_tensor[:, :-1]  \n",
    "print(y_tensor[:,:-1].shape)\n",
    "y_tgt_input = y_tensor[:, 1:]\n",
    "print(y_tensor[:,1:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1b000f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "    \n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4930610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124810\n",
      "487\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(x_src_input)\n",
    "print(BUFFER_SIZE)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(x_src_input) // BATCH_SIZE\n",
    "print(steps_per_epoch)\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b1218d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31203\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(y_src_input)\n",
    "print(BUFFER_SIZE)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(y_src_input) // BATCH_SIZE\n",
    "print(steps_per_epoch)\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "56fafdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124810, 14)\n",
      "(124810, 14)\n"
     ]
    }
   ],
   "source": [
    "print(x_src_input.shape)\n",
    "print(x_tgt_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7576d0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31203, 14)\n",
      "(31203, 14)\n"
     ]
    }
   ],
   "source": [
    "print(y_src_input.shape)\n",
    "print(y_tgt_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b370b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataset = tf.data.Dataset.from_tensor_slices((x_src_input, x_tgt_input))\n",
    "x_dataset = x_dataset.shuffle(BUFFER_SIZE)\n",
    "x_dataset = x_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b0b9c2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3eb8e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = tf.data.Dataset.from_tensor_slices((y_src_input, y_tgt_input))\n",
    "y_dataset = y_dataset.shuffle(BUFFER_SIZE)\n",
    "y_dataset = y_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "18bc5748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5705b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6bf59975",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "VOCAB_SIZE = tokenizer.num_words + 1\n",
    "#단어장 사이즈 = 12001\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9c0f5624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ee9f8c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a13d277c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[    2    33    50 ...     0     0     0]\n",
      " [    2   107  1864 ...     0     0     0]\n",
      " [    2    25    41 ...     0     0     0]\n",
      " ...\n",
      " [    2   577 11551 ...     0     0     0]\n",
      " [    2    39   685 ...     0     0     0]\n",
      " [    2  2539  6365 ...     0     0     0]], shape=(256, 14), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[   33    50    11 ...     0     0     0]\n",
      " [  107  1864   221 ...     0     0     0]\n",
      " [   25    41   870 ...     0     0     0]\n",
      " ...\n",
      " [  577 11551     8 ...     0     0     0]\n",
      " [   39   685  6900 ...     0     0     0]\n",
      " [ 2539  6365    43 ...     0     0     0]], shape=(256, 14), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for src_sample, tgt_sample in x_dataset.take(1):\n",
    "    print(src_sample)\n",
    "    print(tgt_sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1c37c83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[-2.58650369e-04, -9.09738010e-05, -6.95002454e-05, ...,\n",
       "         -2.72757461e-05,  4.43973171e-04,  2.72697420e-04],\n",
       "        [-2.13396779e-04,  1.00372570e-04, -1.39802505e-04, ...,\n",
       "          9.70447945e-05,  1.03016198e-03,  3.25026253e-04],\n",
       "        [-1.03921251e-04,  5.08677447e-04, -1.18027987e-04, ...,\n",
       "          2.87765724e-04,  1.12573034e-03,  1.81514915e-04],\n",
       "        ...,\n",
       "        [-2.06596145e-04,  1.89160801e-05,  6.19022117e-04, ...,\n",
       "         -1.29212067e-03, -3.06078553e-04, -2.13991661e-04],\n",
       "        [ 2.56407919e-04, -6.62493258e-05,  8.30457197e-04, ...,\n",
       "         -1.68347661e-03, -5.19126246e-04, -6.58018325e-05],\n",
       "        [ 7.24128040e-04, -1.53543660e-04,  1.06339168e-03, ...,\n",
       "         -2.03096052e-03, -6.83442806e-04,  4.36616901e-05]],\n",
       "\n",
       "       [[-2.58650369e-04, -9.09738010e-05, -6.95002454e-05, ...,\n",
       "         -2.72757461e-05,  4.43973171e-04,  2.72697420e-04],\n",
       "        [-2.62016983e-04, -3.47299385e-04, -6.46932167e-05, ...,\n",
       "         -4.65591802e-05,  6.50469621e-04,  3.38657061e-04],\n",
       "        [-1.25864550e-04, -7.19340693e-04, -1.46445731e-04, ...,\n",
       "          2.09157934e-05,  1.03973376e-03,  3.44475469e-04],\n",
       "        ...,\n",
       "        [ 2.78944586e-04,  6.74347859e-04, -7.24402431e-04, ...,\n",
       "         -1.07862230e-03,  3.84096289e-04, -2.60938570e-04],\n",
       "        [ 5.99891529e-04,  6.42917468e-04, -4.97742498e-04, ...,\n",
       "         -1.47630472e-03,  2.35128118e-05, -9.61320256e-05],\n",
       "        [ 9.46335669e-04,  5.50955941e-04, -2.13543099e-04, ...,\n",
       "         -1.85237208e-03, -2.62572779e-04,  5.77459832e-05]],\n",
       "\n",
       "       [[-2.58650369e-04, -9.09738010e-05, -6.95002454e-05, ...,\n",
       "         -2.72757461e-05,  4.43973171e-04,  2.72697420e-04],\n",
       "        [-4.46535094e-04, -3.46997345e-04, -2.47774064e-04, ...,\n",
       "         -2.16605054e-04,  4.47335915e-04,  5.92435885e-04],\n",
       "        [-5.64304937e-04, -7.73014151e-04, -3.10329517e-04, ...,\n",
       "         -3.13572207e-04,  5.02328796e-04,  8.03996227e-04],\n",
       "        ...,\n",
       "        [ 7.71288251e-05, -7.01656681e-04,  2.49598408e-04, ...,\n",
       "         -4.87049285e-04, -8.06925120e-04, -3.11215932e-04],\n",
       "        [ 5.25930023e-04, -6.35710836e-04,  4.87304613e-04, ...,\n",
       "         -8.53766105e-04, -9.19324695e-04, -2.40964451e-04],\n",
       "        [ 9.79679637e-04, -5.98088081e-04,  7.41572876e-04, ...,\n",
       "         -1.22750422e-03, -9.98017029e-04, -1.78315109e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.58650369e-04, -9.09738010e-05, -6.95002454e-05, ...,\n",
       "         -2.72757461e-05,  4.43973171e-04,  2.72697420e-04],\n",
       "        [-3.74243595e-04, -1.74181681e-04, -1.14586059e-04, ...,\n",
       "          1.99275266e-04,  7.84449163e-04,  7.32054323e-05],\n",
       "        [-7.12779292e-04, -2.22068862e-04, -1.03753890e-04, ...,\n",
       "          2.46393844e-04,  1.06183358e-03, -3.65323540e-05],\n",
       "        ...,\n",
       "        [-5.79789106e-04,  6.85022329e-04,  4.34925605e-04, ...,\n",
       "         -9.98146832e-04, -9.53501556e-04,  4.08260705e-04],\n",
       "        [-1.91773041e-04,  5.57664083e-04,  6.90591813e-04, ...,\n",
       "         -1.40381954e-03, -1.08076655e-03,  4.44006058e-04],\n",
       "        [ 2.27889250e-04,  4.11657034e-04,  9.55544529e-04, ...,\n",
       "         -1.78441918e-03, -1.16631645e-03,  4.67688224e-04]],\n",
       "\n",
       "       [[-2.58650369e-04, -9.09738010e-05, -6.95002454e-05, ...,\n",
       "         -2.72757461e-05,  4.43973171e-04,  2.72697420e-04],\n",
       "        [-4.14468755e-04, -2.96940725e-05, -7.48043531e-05, ...,\n",
       "         -1.06233383e-04,  6.69542467e-04,  6.42434228e-04],\n",
       "        [-3.71861825e-04, -1.40338481e-04, -1.96504610e-04, ...,\n",
       "         -3.25128785e-04,  9.06848814e-04,  7.74414337e-04],\n",
       "        ...,\n",
       "        [-4.84973280e-04,  2.34891995e-04, -3.81012622e-04, ...,\n",
       "         -5.13795298e-04,  4.28510917e-04, -4.66213882e-04],\n",
       "        [ 1.36130751e-07,  1.25042847e-04, -1.19611024e-04, ...,\n",
       "         -9.48880275e-04,  1.34789705e-04, -2.44706083e-04],\n",
       "        [ 4.94190084e-04,  1.96470592e-05,  1.79289360e-04, ...,\n",
       "         -1.36437360e-03, -1.15702496e-04, -6.08583869e-05]],\n",
       "\n",
       "       [[-2.58650369e-04, -9.09738010e-05, -6.95002454e-05, ...,\n",
       "         -2.72757461e-05,  4.43973171e-04,  2.72697420e-04],\n",
       "        [-8.34416278e-05, -1.59827279e-04,  1.63536606e-04, ...,\n",
       "         -2.02319934e-04,  6.26140507e-04,  3.31300107e-04],\n",
       "        [ 1.00942460e-04, -1.74882269e-04,  3.86016385e-04, ...,\n",
       "         -3.20760882e-04,  6.78354583e-04,  2.96374608e-04],\n",
       "        ...,\n",
       "        [ 1.48537045e-03,  3.95095645e-04,  1.01589272e-03, ...,\n",
       "         -1.78545865e-03, -5.78614709e-04, -5.52591286e-04],\n",
       "        [ 1.82553707e-03,  4.01971309e-04,  1.14090741e-03, ...,\n",
       "         -2.11918843e-03, -7.35346228e-04, -4.06637642e-04],\n",
       "        [ 2.14704964e-03,  3.73930729e-04,  1.30414311e-03, ...,\n",
       "         -2.41625379e-03, -8.49402684e-04, -2.86424358e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c5d42fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "050d52d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none')\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d68fa17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 87s 174ms/step - loss: 3.5152\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 86s 177ms/step - loss: 3.0538\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 86s 177ms/step - loss: 2.8833\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 86s 178ms/step - loss: 2.7563\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 86s 177ms/step - loss: 2.6523\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 86s 177ms/step - loss: 2.5600\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 86s 177ms/step - loss: 2.4732\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 86s 177ms/step - loss: 2.3925\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 86s 178ms/step - loss: 2.3152\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 87s 178ms/step - loss: 2.2417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f24c05b4f40>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "984af7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "VOCAB_SIZE = tokenizer.num_words + 1\n",
    "#단어장 사이즈 = 12001\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e739b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence = \"<start>\", max_len = 15):\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "    \n",
    "    while True:\n",
    "        predict = model(test_tensor)\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis = -1), axis = -1)[:, -1]\n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "\n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ce7a6dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love millionaire clappin clappin dumbing chip raspberry act gling gling beckons beckons beckons '"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f2a445",
   "metadata": {},
   "source": [
    "# 4. 회고\n",
    "\n",
    "4.1 RNN 모델은 Layer의 역할과 shape 변화 추적이 관건\n",
    "\n",
    "    * Simple RNN과 LSTM 모두 Embedding Layer와 RNN Layer, Linear Dense layer 이렇게 세 가지로 구분된다. Simple과 LSTM이 구분되는 것은 RNN Layer의 구조이다. 그러나 RNN Layer의 세부 사항이 다른 걸 제외한다면, Embedding Layer는 문자를 token으로 전환, RNN Layer는 단어 간 연관성 조사, Dense Layer는 단어장 사이즈로 분류 이렇게 큰 틀에선 동일하다.  \n",
    "\n",
    "4.2 가중치가 변하지 않는다는 특징에 유념할 것.\n",
    "    \n",
    "    * RNN 구조의 특징은 아무리 긴 문장을 학습하더라도 모두 동일한 Weigh를 사용한다는 점이다. 이렇게 설계된 이유는 문장 길이에 구애받지 않고 모델이 학습할 수 있는 유연한 환경을 조성하기 위해서라고 추측할 수 있다. \n",
    "\n",
    "4.3 LSTM에서 parameter 계산법\n",
    "\n",
    "    * LSTM은 forget gate에서 weight가 1종류, input gate에서 weight가 2종류 cell state에서 weight가 1 종류가 편성된다. 그래서 simple rnn에 비해 parameter의 개수가 훨씬 많아지는 것이다. 이를 계산하는 법을 따로 필기해 저장해놓았는데 덕분에 LSTM 이해를 수월히 할 수 있었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df5939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
